{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to PyTorch - Tensor Operations and Basics**\n",
        "---"
      ],
      "metadata": {
        "id": "kdrK8uhHjXUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Overview**\n",
        "* This notebook covers the basics of PyTorch, focusing on tensor creation, manipulation, and fundamental operations. Each section explains the purpose of the operations, where they are used, and their relevance to deep learning workflows.\n",
        "---"
      ],
      "metadata": {
        "id": "Q-BYa8S1juwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Check PyTorch Version and Device Availability**\n",
        ">This cell verifies the installed PyTorch version and determines whether a GPU is available for computations. If a GPU is present, it displays its name; otherwise, it defaults to the CPU. This is a crucial first step for optimizing model training and performance."
      ],
      "metadata": {
        "id": "1emd-8NVkPHH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yAC6cjAaS-Uh"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3GBmta7VBO3",
        "outputId": "eedca64e-b43a-433f-9548-152bac67e4f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}.\")\n",
        "else:\n",
        "    print(\"GPU not available. Using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ciqAc0xVGe0",
        "outputId": "2d9dce60-cf03-4fbd-cb16-f07728b46993"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available. Using CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Tensor Creation**\n",
        ">Tensors are the basic data structures in PyTorch, analogous to NumPy arrays but optimized for GPU computations. This cell demonstrates how to create tensors with specific initializations."
      ],
      "metadata": {
        "id": "SF_0V0rCkytn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating basic tensors\n",
        "basic_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(f\"Basic Tensor:\\n{basic_tensor}\\n\\n\")\n",
        "\n",
        "# Empty tensor (uninitialized values)\n",
        "empty_tensor = torch.empty(2, 3)\n",
        "print(f\"Empty Tensor:\\n{empty_tensor}\\n\\n\")\n",
        "\n",
        "# Tensors filled with zeros and ones\n",
        "zeros_tensor = torch.zeros(2, 3)\n",
        "print(f\"Zeros Tensor:\\n{zeros_tensor}\\n\\n\")\n",
        "\n",
        "ones_tensor = torch.ones(2, 3)\n",
        "print(f\"Ones Tensor:\\n{ones_tensor}\\n\\n\")\n",
        "\n",
        "# Random tensor\n",
        "random_tensor = torch.rand(2, 3)\n",
        "print(f\"Random Tensor:\\n{random_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O92509Pik_F9",
        "outputId": "71c5bf8c-f8dc-41a3-db0a-def9eec3e49d"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basic Tensor:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "\n",
            "Empty Tensor:\n",
            "tensor([[-8.6965e-28,  4.4948e-41, -2.9332e-34],\n",
            "        [ 3.1608e-41,  4.0481e-01,  9.1996e-01]])\n",
            "\n",
            "\n",
            "Zeros Tensor:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "\n",
            "Ones Tensor:\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n",
            "\n",
            "Random Tensor:\n",
            "tensor([[0.3699, 0.5012, 0.6380],\n",
            "        [0.0111, 0.4356, 0.1696]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Tensor Creation with Specific Patterns**\n",
        ">This cell introduces common tensor creation patterns, including seeded random values, ranges, and constant values. These methods are useful for initializing weights and building test cases."
      ],
      "metadata": {
        "id": "S4a2stLhlRvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a random seed for reproducibility\n",
        "torch.manual_seed(110)\n",
        "seeded_tensor = torch.rand(2, 3)\n",
        "print(f\"Seeded Random Tensor:\\n{seeded_tensor}\\n\\n\")\n",
        "\n",
        "# Range-based tensors\n",
        "range_tensor = torch.arange(10)  # Sequence from 0 to 9\n",
        "print(f\"Range Tensor:\\n{range_tensor}\\n\\n\")\n",
        "\n",
        "linspace_tensor = torch.linspace(0, 1, steps=5)  # 5 evenly spaced points between 0 and 1\n",
        "print(f\"Linspace Tensor:\\n{linspace_tensor}\\n\\n\")\n",
        "\n",
        "# Identity matrix\n",
        "identity_tensor = torch.eye(3)\n",
        "print(f\"Identity Tensor:\\n{identity_tensor}\\n\\n\")\n",
        "\n",
        "# Tensor with constant values\n",
        "full_tensor = torch.full((3, 3), 5)\n",
        "print(f\"Tensor with All Elements as 5:\\n{full_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtLRWIDTWbqi",
        "outputId": "7e2f7af3-f7ef-4392-9bd0-cd360433c311"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seeded Random Tensor:\n",
            "tensor([[0.7111, 0.0904, 0.5646],\n",
            "        [0.7994, 0.1508, 0.6337]])\n",
            "\n",
            "\n",
            "Range Tensor:\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "\n",
            "\n",
            "Linspace Tensor:\n",
            "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
            "\n",
            "\n",
            "Identity Tensor:\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "\n",
            "\n",
            "Tensor with All Elements as 5:\n",
            "tensor([[5, 5, 5],\n",
            "        [5, 5, 5],\n",
            "        [5, 5, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Tensors with the Same Shape**\n",
        ">These functions are used to create tensors with the same shape as an existing tensor, which is helpful for initializing or modifying model parameters."
      ],
      "metadata": {
        "id": "Xt7UFEP8llKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensors matching the shape of an existing tensor\n",
        "zeros_like_tensor = torch.zeros_like(basic_tensor)\n",
        "print(f\"Zeros Like Tensor:\\n{zeros_like_tensor}\\n\\n\")\n",
        "\n",
        "ones_like_tensor = torch.ones_like(basic_tensor)\n",
        "print(f\"Ones Like Tensor:\\n{ones_like_tensor}\\n\\n\")\n",
        "\n",
        "random_like_tensor = torch.rand_like(basic_tensor, dtype=torch.float32)\n",
        "print(f\"Random Like Tensor:\\n{random_like_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRkASxYuXkgw",
        "outputId": "7db12b48-3193-493f-a234-fa3bd0173c2b"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zeros Like Tensor:\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "\n",
            "\n",
            "Ones Like Tensor:\n",
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1]])\n",
            "\n",
            "\n",
            "Random Like Tensor:\n",
            "tensor([[0.4826, 0.9588, 0.1291],\n",
            "        [0.5870, 0.3136, 0.7080]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Tensor Data Types and Conversions**\n",
        ">This demonstrates how to specify and convert tensor data types, which is critical for ensuring compatibility between operations in deep learning models."
      ],
      "metadata": {
        "id": "svCbFBlyl1Qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying data types\n",
        "int_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.int32)\n",
        "print(f\"Integer Tensor:\\n{int_tensor}\\n\\n\")\n",
        "\n",
        "float_tensor = int_tensor.to(dtype=torch.float32)\n",
        "print(f\"Float Tensor:\\n{float_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBPzvwp9mB-y",
        "outputId": "2db8d66b-1d2a-4809-8504-24a9d5939ee4"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integer Tensor:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n",
            "\n",
            "\n",
            "Float Tensor:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Basic Arithmetic Operations**\n",
        ">Arithmetic operations are performed element-wise and are foundational to defining custom loss functions, scaling, or data transformations."
      ],
      "metadata": {
        "id": "QO7V4e06mJmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sample tensors\n",
        "x1 = torch.rand(2, 3)\n",
        "\n",
        "# Arithmetic operations\n",
        "print(f\"x1 + 2:\\n{x1 + 2}\\n\\n\")\n",
        "print(f\"x1 - 2:\\n{x1 - 2}\\n\\n\")\n",
        "print(f\"x1 * 2:\\n{x1 * 2}\\n\\n\")\n",
        "print(f\"x1 / 2:\\n{x1 / 2}\\n\\n\")\n",
        "print(f\"x1 ** 2:\\n{x1 ** 2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYZgOvo9ZTdz",
        "outputId": "619563b9-426a-4818-9fe4-2838e05fae55"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1 + 2:\n",
            "tensor([[2.0611, 2.7027, 2.1919],\n",
            "        [2.1905, 2.3536, 2.0240]])\n",
            "\n",
            "\n",
            "x1 - 2:\n",
            "tensor([[-1.9389, -1.2973, -1.8081],\n",
            "        [-1.8095, -1.6464, -1.9760]])\n",
            "\n",
            "\n",
            "x1 * 2:\n",
            "tensor([[0.1223, 1.4055, 0.3838],\n",
            "        [0.3810, 0.7072, 0.0481]])\n",
            "\n",
            "\n",
            "x1 / 2:\n",
            "tensor([[0.0306, 0.3514, 0.0960],\n",
            "        [0.0952, 0.1768, 0.0120]])\n",
            "\n",
            "\n",
            "x1 ** 2:\n",
            "tensor([[0.0037, 0.4938, 0.0368],\n",
            "        [0.0363, 0.1250, 0.0006]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Comparison Operations**\n",
        ">Comparison operators return boolean tensors, which are useful for masking or filtering specific elements in deep learning workflows."
      ],
      "metadata": {
        "id": "uNUGcauzmZdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sample tensors\n",
        "tensor_a = torch.randint(0, 10, (3, 3))\n",
        "tensor_b = torch.randint(0, 10, (3, 3))\n",
        "\n",
        "# Comparison operators\n",
        "print(f\"tensor_a > tensor_b:\\n{tensor_a > tensor_b}\\n\\n\")\n",
        "print(f\"tensor_a == tensor_b:\\n{tensor_a == tensor_b}\\n\\n\")\n",
        "print(f\"tensor_a <= tensor_b:\\n{tensor_a <= tensor_b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS2obinVZo5_",
        "outputId": "bf9f545f-2f41-490c-ebb8-73254b3f8aec"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_a > tensor_b:\n",
            "tensor([[False,  True, False],\n",
            "        [False,  True,  True],\n",
            "        [ True,  True,  True]])\n",
            "\n",
            "\n",
            "tensor_a == tensor_b:\n",
            "tensor([[ True, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False]])\n",
            "\n",
            "\n",
            "tensor_a <= tensor_b:\n",
            "tensor([[ True, False,  True],\n",
            "        [ True, False, False],\n",
            "        [False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Matrix Operations**\n",
        ">Matrix and vector operations form the backbone of deep learning, as they represent computations in fully connected and convolutional layers."
      ],
      "metadata": {
        "id": "1KyHGx5cnAzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix operations\n",
        "matrix_a = torch.randint(0, 10, (2, 3))\n",
        "matrix_b = torch.randint(0, 10, (3, 2))\n",
        "\n",
        "# Matrix multiplication\n",
        "matrix_result = torch.matmul(matrix_a, matrix_b)\n",
        "print(f\"Matrix Multiplication Result:\\n{matrix_result}\\n\\n\")\n",
        "\n",
        "# Vector operations\n",
        "vector_a = torch.tensor([1, 2, 3])\n",
        "vector_b = torch.tensor([4, 5, 6])\n",
        "\n",
        "dot_product = torch.dot(vector_a, vector_b)\n",
        "print(f\"Dot Product:\\n{dot_product}\\n\\n\")\n",
        "\n",
        "cross_product = torch.cross(vector_a, vector_b)\n",
        "print(f\"Cross Product:\\n{cross_product}\")\n",
        "\n",
        "# Determinant and inverse\n",
        "square_matrix = torch.randint(size=(3, 3), low=1, high=10, dtype=torch.float32)\n",
        "\n",
        "determinant = torch.det(square_matrix)  # Determinant\n",
        "inverse = torch.inverse(square_matrix)  # Inverse of a matrix\n",
        "\n",
        "print(f\"Square Matrix:\\n{square_matrix}\\n\\n\")\n",
        "print(f\"Determinant:\\n{determinant}\\n\\n\")\n",
        "print(f\"Inverse:\\n{inverse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPK6A1POaNsX",
        "outputId": "6c169983-054b-46c1-cd2f-c1efef9195ec"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication Result:\n",
            "tensor([[61, 38],\n",
            "        [71, 17]])\n",
            "\n",
            "\n",
            "Dot Product:\n",
            "32\n",
            "\n",
            "\n",
            "Cross Product:\n",
            "tensor([-3,  6, -3])\n",
            "Square Matrix:\n",
            "tensor([[4., 9., 4.],\n",
            "        [3., 3., 5.],\n",
            "        [9., 1., 4.]])\n",
            "\n",
            "\n",
            "Determinant:\n",
            "228.99998474121094\n",
            "\n",
            "\n",
            "Inverse:\n",
            "tensor([[ 0.0306, -0.1397,  0.1441],\n",
            "        [ 0.1441, -0.0873, -0.0349],\n",
            "        [-0.1048,  0.3362, -0.0655]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Statistical Operations**\n",
        ">Statistical functions are critical for analyzing data distributions, computing metrics, and applying normalization."
      ],
      "metadata": {
        "id": "kX0XNRkJnWmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical operations\n",
        "stat_tensor = torch.randint(0, 10, (2, 3), dtype=torch.float32)\n",
        "\n",
        "print(f\"Sum:\\n{torch.sum(stat_tensor)}\\n\\n\")\n",
        "print(f\"Mean:\\n{torch.mean(stat_tensor)}\\n\\n\")\n",
        "print(f\"Median:\\n{torch.median(stat_tensor)}\\n\\n\")\n",
        "print(f\"Standard Deviation:\\n{torch.std(stat_tensor)}\\n\\n\")\n",
        "print(f\"Max Value:\\n{torch.max(stat_tensor)}\\n\\n\")\n",
        "print(f\"Min Value:\\n{torch.min(stat_tensor)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIGzeljVndh3",
        "outputId": "16b74db2-8c50-4884-f66a-916d4b4ce9d9"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum:\n",
            "27.0\n",
            "\n",
            "\n",
            "Mean:\n",
            "4.5\n",
            "\n",
            "\n",
            "Median:\n",
            "1.0\n",
            "\n",
            "\n",
            "Standard Deviation:\n",
            "3.987480401992798\n",
            "\n",
            "\n",
            "Max Value:\n",
            "9.0\n",
            "\n",
            "\n",
            "Min Value:\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Tensor Reshaping and Flattening**\n",
        ">Reshaping allows tensors to fit specific model architectures, while flattening is commonly used in transitioning from convolutional to fully connected layers."
      ],
      "metadata": {
        "id": "Q4t9iO4jnnnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping tensors\n",
        "tensor_2d = torch.rand(4, 4)\n",
        "\n",
        "reshaped_tensor = tensor_2d.reshape(2, 2, 4)\n",
        "print(f\"Reshaped Tensor:\\n{reshaped_tensor}\\n\\n\")\n",
        "\n",
        "flattened_tensor = tensor_2d.flatten()\n",
        "print(f\"Flattened Tensor:\\n{flattened_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNZ7IyBDdiuk",
        "outputId": "2a29406d-6928-4b68-cd88-8d077d063f1b"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped Tensor:\n",
            "tensor([[[0.8859, 0.0505, 0.2996, 0.7855],\n",
            "         [0.7175, 0.7284, 0.8830, 0.8519]],\n",
            "\n",
            "        [[0.9472, 0.5648, 0.5515, 0.6643],\n",
            "         [0.2953, 0.6694, 0.5809, 0.8117]]])\n",
            "\n",
            "\n",
            "Flattened Tensor:\n",
            "tensor([0.8859, 0.0505, 0.2996, 0.7855, 0.7175, 0.7284, 0.8830, 0.8519, 0.9472,\n",
            "        0.5648, 0.5515, 0.6643, 0.2953, 0.6694, 0.5809, 0.8117])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Cloning and In-place Operations**\n",
        ">Cloning ensures that a copy of the tensor is created for independent manipulation, while in-place operations directly modify the original tensor."
      ],
      "metadata": {
        "id": "7c82uBw4nzBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning and in-place operations\n",
        "tensor_original = torch.rand(2, 3)\n",
        "tensor_clone = tensor_original.clone()\n",
        "\n",
        "print(f\"Original Tensor ID: {id(tensor_original)}\\n\\n\")\n",
        "print(f\"Cloned Tensor ID: {id(tensor_clone)}\\n\\n\")\n",
        "\n",
        "# In-place addition\n",
        "tensor_original.add_(tensor_clone)\n",
        "print(f\"In-place Added Tensor:\\n{tensor_original}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhhLw2xCd2Xv",
        "outputId": "28fb0829-4542-450b-d4dc-bfa5d777fd8b"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor ID: 137764237015248\n",
            "\n",
            "\n",
            "Cloned Tensor ID: 137764237004048\n",
            "\n",
            "\n",
            "In-place Added Tensor:\n",
            "tensor([[0.1132, 1.0897, 1.4572],\n",
            "        [1.5520, 0.3437, 1.1513]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Advanced Tensor Operations**\n",
        ">These operations are essential for advanced linear algebra computations, especially in tasks like solving systems of equations or computing eigenvalues."
      ],
      "metadata": {
        "id": "BCUOKTEWoS9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose and determinant\n",
        "square_tensor = torch.rand(3, 3)\n",
        "\n",
        "transposed = torch.transpose(square_tensor, 0, 1)\n",
        "print(f\"Transposed Tensor:\\n{transposed}\\n\\n\")\n",
        "\n",
        "determinant = torch.det(square_tensor)\n",
        "print(f\"Determinant:\\n{determinant}\\n\\n\")\n",
        "\n",
        "# Advanced element-wise operations\n",
        "tensor_a = torch.tensor([-1.0, -2.0, -3.0])\n",
        "\n",
        "absolute_values = torch.abs(tensor_a)  # Absolute values\n",
        "print(f\"Absolute Values:\\n{absolute_values}\\n\\n\")\n",
        "\n",
        "tensor_b = torch.tensor([1.9, 2.7, 3.2])\n",
        "rounded = torch.round(tensor_b)  # Rounding values\n",
        "floored = torch.floor(tensor_b)  # Floor operation\n",
        "ceiled = torch.ceil(tensor_b)    # Ceiling operation\n",
        "\n",
        "print(f\"Rounded:\\n{rounded}\\n\\n\")\n",
        "print(f\"Floored:\\n{floored}\\n\\n\")\n",
        "print(f\"Ceiled:\\n{ceiled}\\n\\n\")\n",
        "\n",
        "# Clamp values within a range\n",
        "clamped = torch.clamp(tensor_b, min=2.0, max=3.0)\n",
        "print(f\"Clamped Tensor (2.0 to 3.0):\\n{clamped}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9lzEK3heH8w",
        "outputId": "98e1cd34-317e-4865-8998-b5f89401621e"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transposed Tensor:\n",
            "tensor([[0.7482, 0.9570, 0.4607],\n",
            "        [0.8451, 0.0871, 0.8130],\n",
            "        [0.8652, 0.3297, 0.3212]])\n",
            "\n",
            "\n",
            "Determinant:\n",
            "0.32738903164863586\n",
            "\n",
            "\n",
            "Absolute Values:\n",
            "tensor([1., 2., 3.])\n",
            "\n",
            "\n",
            "Rounded:\n",
            "tensor([2., 3., 3.])\n",
            "\n",
            "\n",
            "Floored:\n",
            "tensor([1., 2., 3.])\n",
            "\n",
            "\n",
            "Ceiled:\n",
            "tensor([2., 3., 4.])\n",
            "\n",
            "\n",
            "Clamped Tensor (2.0 to 3.0):\n",
            "tensor([2.0000, 2.7000, 3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Activation Functions**\n",
        ">Activation functions introduce non-linearity into deep learning models:\n",
        "* ReLU: Replaces negatives with 0.\n",
        "* Sigmoid: Compresses output between (0, 1).\n",
        "* Tanh: Compresses output between (-1, 1).\n",
        "* Softmax: Converts outputs into probabilities.\n"
      ],
      "metadata": {
        "id": "r7ak5BmSo24_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation functions\n",
        "input_values = torch.linspace(-5, 5, steps=10)\n",
        "\n",
        "relu_output = torch.relu(input_values)  # Rectified Linear Unit\n",
        "sigmoid_output = torch.sigmoid(input_values)  # Sigmoid\n",
        "tanh_output = torch.tanh(input_values)  # Hyperbolic tangent\n",
        "softmax_output = torch.softmax(input_values, dim=0)  # Softmax along a dimension\n",
        "\n",
        "print(f\"Input Values:\\n{input_values}\\n\\n\")\n",
        "print(f\"ReLU Activation:\\n{relu_output}\\n\\n\")\n",
        "print(f\"Sigmoid Activation:\\n{sigmoid_output}\\n\\n\")\n",
        "print(f\"Tanh Activation:\\n{tanh_output}\\n\\n\")\n",
        "print(f\"Softmax Activation:\\n{softmax_output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It94FUFSo2tH",
        "outputId": "5bf911c6-bc4e-4c98-bf31-ed965d97ddd8"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Values:\n",
            "tensor([-5.0000, -3.8889, -2.7778, -1.6667, -0.5556,  0.5556,  1.6667,  2.7778,\n",
            "         3.8889,  5.0000])\n",
            "\n",
            "\n",
            "ReLU Activation:\n",
            "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5556, 1.6667, 2.7778, 3.8889,\n",
            "        5.0000])\n",
            "\n",
            "\n",
            "Sigmoid Activation:\n",
            "tensor([0.0067, 0.0201, 0.0585, 0.1589, 0.3646, 0.6354, 0.8411, 0.9415, 0.9799,\n",
            "        0.9933])\n",
            "\n",
            "\n",
            "Tanh Activation:\n",
            "tensor([-0.9999, -0.9992, -0.9923, -0.9311, -0.5047,  0.5047,  0.9311,  0.9923,\n",
            "         0.9992,  0.9999])\n",
            "\n",
            "\n",
            "Softmax Activation:\n",
            "tensor([3.0455e-05, 9.2514e-05, 2.8103e-04, 8.5370e-04, 2.5933e-03, 7.8778e-03,\n",
            "        2.3931e-02, 7.2695e-02, 2.2083e-01, 6.7082e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **In-Place Operations**\n",
        ">In-place operations save memory but modify the original tensor, which can be risky if gradients are being tracked. The underscore at the end of the function name indicates an in-place operation."
      ],
      "metadata": {
        "id": "_2ICY8c2pxeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In-place operations\n",
        "tensor_a = torch.rand(2, 3)\n",
        "tensor_b = torch.rand(2, 3)\n",
        "\n",
        "tensor_a.add_(tensor_b)  # In-place addition\n",
        "print(f\"In-place Addition Result:\\n{tensor_a}\\n\\n\")\n",
        "\n",
        "tensor_a.relu_()  # In-place ReLU activation\n",
        "print(f\"In-place ReLU Activation:\\n{tensor_a}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_bROQ4_puxm",
        "outputId": "51b37e9f-5dab-43e7-83ad-d30117870746"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-place Addition Result:\n",
            "tensor([[1.5029, 1.0747, 1.5714],\n",
            "        [0.8316, 1.2008, 0.6204]])\n",
            "\n",
            "\n",
            "In-place ReLU Activation:\n",
            "tensor([[1.5029, 1.0747, 1.5714],\n",
            "        [0.8316, 1.2008, 0.6204]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Squeeze and Unsqueeze Operations**\n",
        ">- `unsqueeze()` adds a new dimension of size 1 at the specified index.\n",
        "- `squeeze()` removes dimensions of size 1, which is useful for reducing the rank of tensors after certain operations (e.g., after a convolution)."
      ],
      "metadata": {
        "id": "KQ25XA3yqGB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Squeeze and Unsqueeze\n",
        "tensor = torch.rand(1, 20, 1, 10)\n",
        "\n",
        "# Unsqueeze adds a new dimension at position 0\n",
        "unsqueezed_tensor = tensor.unsqueeze(0)  # Adds a batch dimension\n",
        "print(f\"Unsqueezed Tensor Shape:\\n{unsqueezed_tensor.shape}\\n\\n\")\n",
        "\n",
        "# Squeeze removes dimensions of size 1\n",
        "squeezed_tensor = tensor.squeeze(0)  # Removes the batch dimension (size 1)\n",
        "print(f\"Squeezed Tensor Shape:\\n{squeezed_tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9CObqXuqWkW",
        "outputId": "7cf0335e-378f-445a-bd10-ecaf39df1aeb"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsqueezed Tensor Shape:\n",
            "torch.Size([1, 1, 20, 1, 10])\n",
            "\n",
            "\n",
            "Squeezed Tensor Shape:\n",
            "torch.Size([20, 1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **NumPy Interoperability**\n",
        ">Interoperability between PyTorch and NumPy ensures compatibility with Python libraries. This is especially useful for scientific computing and visualizations."
      ],
      "metadata": {
        "id": "osvOL_TGpJ74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "GFO7sX08qayl"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion between PyTorch tensors and NumPy arrays\n",
        "torch_to_numpy = torch.tensor([1.0, 2.0, 3.0]).numpy()  # Tensor to NumPy\n",
        "numpy_to_torch = torch.from_numpy(np.array([4.0, 5.0, 6.0]))  # NumPy to Tensor\n",
        "\n",
        "print(f\"Converted to NumPy:\\n{torch_to_numpy}\\n\\n\")\n",
        "print(f\"Converted to PyTorch Tensor:\\n{numpy_to_torch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oamXxMBkpFmF",
        "outputId": "b304e832-053f-4920-af19-ce5577a6a574"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted to NumPy:\n",
            "[1. 2. 3.]\n",
            "\n",
            "\n",
            "Converted to PyTorch Tensor:\n",
            "tensor([4., 5., 6.], dtype=torch.float64)\n"
          ]
        }
      ]
    }
  ]
}