{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Binary Classification of Breast Cancer using PyTorch**\n",
        "---"
      ],
      "metadata": {
        "id": "TxaCprdQp0cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Overview**\n",
        ">This notebook demonstrates a step-by-step implementation of a binary classification task using PyTorch to predict whether breast cancer is malignant or benign based on clinical features. The dataset is preprocessed by scaling the features using `StandardScaler` and encoding the target labels into a numerical format. A simple single-layer neural network, equivalent to logistic regression, is built using PyTorch's `nn.Module`. The model is trained using the Binary Cross-Entropy Loss with logits (`BCEWithLogitsLoss`) and optimized with Stochastic Gradient Descent (SGD). A training loop is implemented to perform forward and backward passes, calculate the loss, and update model parameters iteratively. Finally, the model is evaluated on the test dataset to compute its accuracy, showcasing the entire workflow of training and testing a binary classifier with PyTorch."
      ],
      "metadata": {
        "id": "5EfxpWrDp3He"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Install Required Libraries**\n",
        ">Installs the `torchinfo` library, which is useful for summarizing PyTorch models."
      ],
      "metadata": {
        "id": "dvpH079jqJ7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xka46GnjX9l",
        "outputId": "da9d2837-7c01-4030-f7d7-1bd191ea0e7a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Import Required Libraries**\n",
        ">- `torch`: Core PyTorch library.\n",
        "- `torch.nn`: Module for defining and training neural networks.\n",
        "- `pandas`: For loading and preprocessing the dataset.\n",
        "- `numpy`: To handle numerical operations.\n",
        "- `sklearn`: Provides tools for splitting data, scaling features, and encoding labels.\n",
        "- `torchinfo`: To summarize the PyTorch model architecture (not used in this notebook)."
      ],
      "metadata": {
        "id": "UWL-BaTRqP9Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "LGd5AbHdbJOd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Load and Preprocess the Dataset**\n",
        ">- Loads the Breast Cancer Wisconsin dataset from a GitHub link.\n",
        "- Drops unnecessary columns (`id` and `Unnamed: 32`) since they are not relevant for model training."
      ],
      "metadata": {
        "id": "GRqTVfT7qeiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv\")"
      ],
      "metadata": {
        "id": "ZtykVMBhlKlX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=[\"id\", \"Unnamed: 32\"], inplace=True)"
      ],
      "metadata": {
        "id": "kWMeiwy3lu9j"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Split Data into Training and Testing Sets**\n",
        ">Splits the dataset into training (80%) and testing (20%) sets.\n",
        " - `X`: Feature columns.\n",
        " - `y`: Target column (diagnosis).\n",
        " - `random_state=42`: Ensures reproducibility."
      ],
      "metadata": {
        "id": "iwf2QAY_qqUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0],\n",
        "                                                    test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "EnlxCc_9lwGT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Feature Scaling and Label Encoding**\n",
        ">- **Feature Scaling**: Standardizes the feature values to have a mean of 0 and a standard deviation of 1 using StandardScaler. This is important to ensure faster and stable convergence.\n",
        "- **Label Encoding**: Converts the categorical labels (e.g., \"M\" and \"B\") into numerical format (0 and 1)."
      ],
      "metadata": {
        "id": "r3qHGiU6q0Ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "8TjpnLAjl1dG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "1wHOFDhcl3Rt"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Convert Data into PyTorch Tensors**\n",
        ">- Converts numpy arrays into PyTorch tensors.\n",
        "- Adds an extra dimension to `y_train_tensor` and `y_test_tensor` using `.unsqueeze(1)` to match the model's output shape (`batch_size, 1`).\n",
        "- Data type is explicitly set to `torch.float`."
      ],
      "metadata": {
        "id": "4UxQEFgCq_5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "y_test_tensor = torch.from_numpy(y_test).float()"
      ],
      "metadata": {
        "id": "uZJF9412l5kg"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Define the Neural Network Model**\n",
        ">Defines a simple single-layer neural network (logistic regression).\n",
        " - The `forward()` method computes the linear transformation without applying a sigmoid activation.\n",
        " - **Input**: `num_features` (number of input features).\n",
        " - **Output**: A single value (logit)."
      ],
      "metadata": {
        "id": "B4wFKZUorPdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron(nn.Module):\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(num_features, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, features):\n",
        "    # return self.sigmoid(self.linear(features))\n",
        "    return self.linear(features)"
      ],
      "metadata": {
        "id": "tAF8gP4hl7V4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Initialize Model, Loss Function, and Optimizer**\n",
        ">- **Model**: Instantiates the Neuron model with input size equal to the number of features.\n",
        "- **Loss Function**: BCEWithLogitsLoss combines the sigmoid activation and binary cross-entropy loss in a numerically stable way.\n",
        "- **Optimizer**: Stochastic Gradient Descent (SGD) with a learning rate of 0.1."
      ],
      "metadata": {
        "id": "etL6DBKFrodm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.BCELoss()"
      ],
      "metadata": {
        "id": "yRbR29ttnHGZ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Neuron(X_train_tensor.shape[1])\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "xwmDKHZ7nIo2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_data=X_train_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsHv_QZTpaS-",
        "outputId": "7f520d32-fb58-4c6b-91e0-5e4b8870e8bd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Neuron                                   [455, 1]                  --\n",
              "├─Linear: 1-1                            [455, 1]                  31\n",
              "├─Sigmoid: 1-2                           [455, 1]                  --\n",
              "==========================================================================================\n",
              "Total params: 31\n",
              "Trainable params: 31\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.01\n",
              "==========================================================================================\n",
              "Input size (MB): 0.05\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.06\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Training Loop**\n",
        ">- Loops over 25 epochs to train the model.\n",
        "- **Forward Pass**: Computes predictions for the training data.\n",
        "- **Loss Calculation**: Computes the binary cross-entropy loss with logits.\n",
        "- **Backward Pass**: Calculates gradients using `.backward()`.\n",
        "- **Optimizer Step**: Updates model parameters using `optimizer.step()`.\n",
        "- Prints the loss at each epoch to monitor training progress.\n"
      ],
      "metadata": {
        "id": "3QaFdkK9r52R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(25):\n",
        "    y_pred = model(X_train_tensor)\n",
        "    l = loss(y_pred, y_train_tensor.unsqueeze(1).float())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Loss: {l.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP8sgBVGoLcT",
        "outputId": "ad68243f-7a91-4abd-a3ff-ddf0a95473f4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.7291861772537231\n",
            "Epoch: 2, Loss: 0.5418397188186646\n",
            "Epoch: 3, Loss: 0.44454148411750793\n",
            "Epoch: 4, Loss: 0.3867309093475342\n",
            "Epoch: 5, Loss: 0.3481771647930145\n",
            "Epoch: 6, Loss: 0.3203520178794861\n",
            "Epoch: 7, Loss: 0.2991158664226532\n",
            "Epoch: 8, Loss: 0.28222930431365967\n",
            "Epoch: 9, Loss: 0.26837706565856934\n",
            "Epoch: 10, Loss: 0.2567354738712311\n",
            "Epoch: 11, Loss: 0.24676178395748138\n",
            "Epoch: 12, Loss: 0.23808303475379944\n",
            "Epoch: 13, Loss: 0.23043392598628998\n",
            "Epoch: 14, Loss: 0.22362013161182404\n",
            "Epoch: 15, Loss: 0.21749570965766907\n",
            "Epoch: 16, Loss: 0.2119486927986145\n",
            "Epoch: 17, Loss: 0.20689138770103455\n",
            "Epoch: 18, Loss: 0.20225408673286438\n",
            "Epoch: 19, Loss: 0.19798055291175842\n",
            "Epoch: 20, Loss: 0.19402477145195007\n",
            "Epoch: 21, Loss: 0.19034862518310547\n",
            "Epoch: 22, Loss: 0.18692027032375336\n",
            "Epoch: 23, Loss: 0.18371275067329407\n",
            "Epoch: 24, Loss: 0.18070323765277863\n",
            "Epoch: 25, Loss: 0.17787204682826996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Model Evaluation on Test Data**\n",
        ">- **Disables Gradient Calculation**: Using `torch.no_grad()` reduces memory usage during evaluation.\n",
        "- **Model Prediction**: Passes test data through the model and applies the sigmoid activation to convert logits into probabilities.\n",
        "- **Thresholding**: Converts probabilities into binary predictions using a threshold of `0.5`.\n",
        "- **Accuracy Calculation**: Computes the fraction of correct predictions.\n",
        "- Prints the test accuracy as a percentage."
      ],
      "metadata": {
        "id": "uGd5h5z4sLC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model.forward(X_test_tensor)\n",
        "  y_pred_class = (y_pred > 0.5).float()\n",
        "  accuracy = (y_pred_class == y_test_tensor).float().mean()\n",
        "\n",
        "  print(f\"Test Accuracy: {accuracy.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YumgQP3tor75",
        "outputId": "a423bd62-b197-4d5e-a2b7-ff0829baa8c0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5301631093025208\n"
          ]
        }
      ]
    }
  ]
}