{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Using PyTorch Dataset and DataLoader for Breast Cancer Detection with a Simple Neural Network**\n",
        "---"
      ],
      "metadata": {
        "id": "hii4QR0Blkc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Overview**\n",
        ">This code demonstrates the use of PyTorch's Dataset and DataLoader classes for managing and batching data in a binary classification task. It focuses on classifying breast cancer cases as malignant or benign using a simple neural network. The dataset is preprocessed by cleaning irrelevant columns, splitting it into training and test sets, scaling the features, and encoding labels for compatibility with PyTorch. A custom Dataset class is implemented to encapsulate the features and labels, while DataLoader is used to handle batching and shuffling of the data during training and evaluation. A single-layer neural network is then defined, trained using Binary Cross-Entropy Loss, and optimized with Stochastic Gradient Descent. Finally, the model is evaluated for accuracy, showcasing the efficient data handling capabilities provided by Dataset and DataLoader."
      ],
      "metadata": {
        "id": "TgShE_wYluyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Importing Libraries**\n",
        ">Import essential libraries for:\n",
        " - Handling data (`pandas`, `numpy`).\n",
        " - Preprocessing (`StandardScaler`, `LabelEncoder`).\n",
        " - Machine learning and neural network implementation (`torch` and `torch.nn`)."
      ],
      "metadata": {
        "id": "rTp1Gqw8lzV9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VXHSDri6l21"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Loading and Cleaning the Dataset**\n",
        ">- **Dataset**: A CSV file containing breast cancer data is loaded directly from GitHub. <br>\n",
        "- **Cleaning**: Irrelevant columns (`id` and `Unnamed: 32`) are removed to retain only meaningful features and the target label."
      ],
      "metadata": {
        "id": "l6iMlrXSmHUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv\")"
      ],
      "metadata": {
        "id": "unjJ0zjlQHZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=[\"id\", \"Unnamed: 32\"], inplace=True)"
      ],
      "metadata": {
        "id": "Wtt8yB21WpTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Splitting the Data into Training and Test Sets**\n",
        ">- Splitting: The data is divided into:\n",
        " - Features (`X`) — all columns except the first.\n",
        " - Labels (`y`) — the first column. <br>\n",
        "- 80% of the data is used for training, and 20% is used for testing."
      ],
      "metadata": {
        "id": "FntuOOWdmXHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0],\n",
        "                                                    test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ci-YamTFWqpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Data Scaling and Encoding**\n",
        ">- **Scaling**: Standardizes the feature values for better performance during training.\n",
        "- **Encoding**: Converts string labels (`malignant`, `benign`) into numeric values (0 or 1) for compatibility with PyTorch."
      ],
      "metadata": {
        "id": "q7k95jhFmtDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Zzlcv1Z5WxR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "SH9q0xGqWzsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Converting Data to PyTorch Tensors**\n",
        "> Converts numpy arrays for features and labels into PyTorch tensors. Tensors are necessary for PyTorch operations.\n"
      ],
      "metadata": {
        "id": "YxnQelUhm6VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "y_test_tensor = torch.from_numpy(y_test).float()"
      ],
      "metadata": {
        "id": "egZZ1TDsW2-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating a Custom Dataset Class**\n",
        ">- A custom dataset class inherits from `torch.utils.data.Dataset`.\n",
        "- Provides methods to retrieve:\n",
        " - The total number of samples (`__len__`).\n",
        " - A specific sample and label by index (`__getitem__`)."
      ],
      "metadata": {
        "id": "jiDruOdSnDVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "cyliZF0gW9Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparing DataLoaders**\n",
        ">- Wraps the datasets in `DataLoader` objects for:\n",
        " - Batch processing (batch size = 32).\n",
        " - Shuffling the data for randomness."
      ],
      "metadata": {
        "id": "5UFjiG7YnVBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)"
      ],
      "metadata": {
        "id": "dsmKUCYfXCim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "SC__SZgGXF4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Defining the Neural Network**\n",
        ">- Implements a single-layer neural network with:\n",
        " - One linear layer (`nn.Linear`) for mapping features to the output.\n",
        " - A forward method defining the computation for the input data."
      ],
      "metadata": {
        "id": "YW1ktEehncJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron(nn.Module):\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(num_features, 1)\n",
        "\n",
        "  def forward(self, features):\n",
        "    return self.linear(features)"
      ],
      "metadata": {
        "id": "Y6lJpSabXMeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initializing the Model, Loss, and Optimizer**\n",
        ">- **Loss Function**: `BCELoss` (Binary Cross-Entropy Loss) for binary classification tasks.\n",
        "- **Model**: An instance of the Neuron class initialized with the number of features.\n",
        "- **Optimizer**: Stochastic Gradient Descent (`SGD`) with a learning rate of 0.1."
      ],
      "metadata": {
        "id": "b2PP6k88nlEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.BCELoss()\n",
        "model = Neuron(X_train_tensor.shape[1])\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "KXsDEu6LXXou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training the Model**\n",
        ">- **Epoch Loop**: Runs the training for 25 iterations.\n",
        "- **Batch Loop**: Iterates through batches of training data.\n",
        "- **Forward Pass**: Computes the model's predictions.\n",
        "- **Loss Calculation**: Compares predictions to actual labels.\n",
        "- **Backward Pass**: Updates model parameters using the gradient of the loss.\n",
        "- **Logging**: Prints loss after each epoch."
      ],
      "metadata": {
        "id": "STWyiJl4n3nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(25):\n",
        "  for features, labels in train_loader:\n",
        "    output = model(features)\n",
        "\n",
        "    l = loss(output, labels.unsqueeze(1))\n",
        "    optimizer.zero_grad()\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch: {epoch} Loss: {l.item()}\")"
      ],
      "metadata": {
        "id": "a4Wf_57CXerd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating the Model**\n",
        ">- **Evaluation Mode**: Disables gradient calculation to speed up testing.\n",
        "- **Predictions**: Applies a sigmoid function to map outputs to probabilities, then rounds to binary values.\n",
        "- **Accuracy Calculation**: Compares predictions with actual labels.\n",
        "- **Result**: Prints the average accuracy over all test batches."
      ],
      "metadata": {
        "id": "BnoEtMcioMN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "accuracy_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for features, labels in test_loader:\n",
        "    output = model(features)\n",
        "    output = torch.round(torch.sigmoid(output))\n",
        "    accuracy = (output == labels.unsqueeze(1)).float().mean()\n",
        "    accuracy_list.append(accuracy)\n",
        "\n",
        "print(f\"Accuracy: {sum(accuracy_list) / len(accuracy_list)}\")"
      ],
      "metadata": {
        "id": "5WhMHZ3FX4Hm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}